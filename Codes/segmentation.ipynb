{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('env37park': venv)"
  },
  "interpreter": {
   "hash": "8c22355d983f3706eade0d6c80f8a886130d704432e0e0922490321cd4d5be40"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nConfigurations:\nBACKBONE                       resnet101\nBACKBONE_STRIDES               [4, 8, 16, 32, 64]\nBATCH_SIZE                     1\nBBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\nCOMPUTE_BACKBONE_SHAPE         None\nDETECTION_MAX_INSTANCES        100\nDETECTION_MIN_CONFIDENCE       0.7\nDETECTION_NMS_THRESHOLD        0.3\nFPN_CLASSIF_FC_LAYERS_SIZE     1024\nGPU_COUNT                      1\nGRADIENT_CLIP_NORM             5.0\nIMAGES_PER_GPU                 1\nIMAGE_CHANNEL_COUNT            3\nIMAGE_MAX_DIM                  1024\nIMAGE_META_SIZE                93\nIMAGE_MIN_DIM                  800\nIMAGE_MIN_SCALE                0\nIMAGE_RESIZE_MODE              square\nIMAGE_SHAPE                    [1024 1024    3]\nLEARNING_MOMENTUM              0.9\nLEARNING_RATE                  0.001\nLOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\nMASK_POOL_SIZE                 14\nMASK_SHAPE                     [28, 28]\nMAX_GT_INSTANCES               100\nMEAN_PIXEL                     [123.7 116.8 103.9]\nMINI_MASK_SHAPE                (56, 56)\nNAME                           coco\nNUM_CLASSES                    81\nPOOL_SIZE                      7\nPOST_NMS_ROIS_INFERENCE        1000\nPOST_NMS_ROIS_TRAINING         2000\nPRE_NMS_LIMIT                  6000\nROI_POSITIVE_RATIO             0.33\nRPN_ANCHOR_RATIOS              [0.5, 1, 2]\nRPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\nRPN_ANCHOR_STRIDE              1\nRPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\nRPN_NMS_THRESHOLD              0.7\nRPN_TRAIN_ANCHORS_PER_IMAGE    256\nSTEPS_PER_EPOCH                1000\nTOP_DOWN_PYRAMID_SIZE          256\nTRAIN_BN                       False\nTRAIN_ROIS_PER_IMAGE           200\nUSE_MINI_MASK                  True\nUSE_RPN_ROIS                   True\nVALIDATION_STEPS               50\nWEIGHT_DECAY                   0.0001\n\n\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcnn.model as modellib\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from mrcnn import utils, visualize\n",
    "\n",
    "import coco\n",
    "import parameters\n",
    "from imantics import Polygons, Mask\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(parameters.RESULTS_PATH, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(parameters.MODEL_PATH, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cars(image,points,alpha=0.1):\n",
    "\n",
    "    output_image = image.copy()\n",
    "\n",
    "    for contours in points:\n",
    "        contours = np.array(contours)\n",
    "        #print(contours)\n",
    "        image = cv2.fillPoly(image, pts =[contours], color=parameters.COLOR_BLUE)\n",
    "        image = cv2.polylines(image, pts =[contours], isClosed=True, color=parameters.COLOR_EDGES, thickness=2)\n",
    "    output_image = cv2.addWeighted(image, alpha, output_image, 1 - alpha,0, output_image)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_points(rgb_image):\n",
    "\n",
    "    results = model.detect([rgb_image], verbose=0)\n",
    "    r = results[0]\n",
    "    car_points = []\n",
    "\n",
    "    for i in range(r['rois'].shape[0]):\n",
    "        if class_names[r['class_ids'][i]] in parameters.CLASS_NAMES:\n",
    "            mask_image = np.array(r['masks'][:, :, i]*1.0)\n",
    "            polygons = Mask(mask_image).polygons()\n",
    "            car_points.append(polygons.points[0])\n",
    "    return car_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr_image = cv2.imread(parameters.DATA_PATH+'espacio-libre.jpg')\n",
    "rgb_image = cv2.cvtColor(bgr_image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "car_points = get_car_points(rgb_image)\n",
    "        \n",
    "bgr_image = plot_cars(bgr_image,car_points,alpha=0.4)\n",
    "\n",
    "cv2.imshow('soel',bgr_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture(parameters.DATA_PATH+'stace_park3.mp4')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    "\n",
    "    #frame = cv2.resize(frame,(300,300))\n",
    "    # Display the resulting frame\n",
    "    rgb_image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    car_points = get_car_points(rgb_image)\n",
    "            \n",
    "    frame = plot_cars(frame,car_points,alpha=0.4)\n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}